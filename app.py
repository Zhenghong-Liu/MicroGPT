import streamlit as st
import torch
from transformers import AutoTokenizer
import os
import sys

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ Python è·¯å¾„ä¸­
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from model.microGPT import MicroGPT
from utils.utils import sample_output

# ==================== æ¨¡å‹é…ç½® ====================
MODEL_WEIGHTS_PATH = "./assert/micro_gpt_chat.pth"
DATA_DIR = "./dataset"

VOCAB_SIZE = 6400
D_MODEL = 512
NHEAD = 8
NUM_LAYERS = 12
D_FF = D_MODEL * 4
DROPOUT = 0.0

DEVICE = torch.device("cpu")

# ==================== è‡ªå®šä¹‰ CSS æ ·å¼ ====================
st.markdown("""
<style>
    .main {
        background-color: #0a0a0a;
        color: #e0e0e0;
        font-family: 'Segoe UI', sans-serif;
    }
    .title {
        text-align: center;
        font-size: 2.2em;
        margin-bottom: 0.5em;
        
    }
    .subtitle {
        text-align: center;
        font-size: 1.1em;
        color: #999999;
        margin-bottom: 1.5em;
    }
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
        padding: 1rem;
        max-width: 800px;
        margin: auto;
    }
    .message {
        display: flex;
        align-items: flex-start;
        margin-bottom: 1rem;
        max-width: 80%;
    }
    .user-message {
        flex-direction: row-reverse;
    }
    
    .message-text {
        color: #333;
        padding: 0.8rem 1rem;
        border-radius: 12px;
        line-height: 1.5;
        word-wrap: break-word;
    }
    .user-message .message-text {
        background-color: #e6f4ff;
    }
    .footer {
        text-align: center;
        color: #777;
        font-size: 0.9em;
        margin-top: 2rem;
        opacity: 0.7;
    }
    .sidebar-title {
        color: #ffffff;
        margin-bottom: 0.5rem;
    }
    .slider-label {
        color: #bbb;
        font-size: 0.9em;
    }
    .btn-primary {
        background-color: #4a4a4a;
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 8px;
        cursor: pointer;
        font-size: 0.9em;
    }
    .btn-primary:hover {
        background-color: #666;
    }
            
    .avatar {
        width: 40px;
        height: 38px;
        border-radius: 50%;
        margin-right: 0.8rem;
        margin-left: 1.0rem;
        background-color: #000;
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 1.0em;
        color: white;
    }
</style>
""", unsafe_allow_html=True)


# ==================== åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨ ====================
@st.cache_resource
def load_model_and_tokenizer():
    try:
        tokenizer = AutoTokenizer.from_pretrained(DATA_DIR)
        global VOCAB_SIZE
        VOCAB_SIZE = len(tokenizer)

        model = MicroGPT(VOCAB_SIZE, D_MODEL, NHEAD, NUM_LAYERS, D_FF, DROPOUT)
        state_dict = torch.load(MODEL_WEIGHTS_PATH, map_location='cpu')
        model.load_state_dict(state_dict)
        model = model.to(DEVICE, dtype=torch.bfloat16)
        model.eval()

        # st.success(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè¿è¡Œåœ¨ {DEVICE} ä¸Šã€‚")
        return model, tokenizer
    except Exception as e:
        st.error(f"âŒ åŠ è½½å¤±è´¥: {e}")
        st.stop()

# ==================== ä¸»å‡½æ•° ====================
def main():
    st.set_page_config(
        page_title="MicroGPT",
        page_icon="ğŸ§ ",
        layout="wide"
    )

    # === é¡µé¢é¡¶éƒ¨æ ‡é¢˜ä¸æç¤º ===
    col1, col2, col3 = st.columns([1, 3, 1])
    with col2:
        st.markdown('<div class="title">ä½ å¥½ï¼Œæˆ‘æ˜¯MicroGPT</div>', unsafe_allow_html=True)
        st.markdown('<div class="subtitle">å†…å®¹å®Œå…¨ç”±AIç”Ÿæˆï¼Œè¯·åŠ¡å¿…ä»”ç»†ç”„åˆ«<br>Content AI-generated, please discern with care</div>', unsafe_allow_html=True)

    # === ä¾§è¾¹æ è®¾ç½® ===
    with st.sidebar:
        st.markdown('<div class="sidebar-title">âš™ï¸ æ¨ç†å‚æ•°</div>', unsafe_allow_html=True)
        temperature = st.slider(
            "æ¸©åº¦ (Temperature)",
            min_value=0.01,
            max_value=1.5,
            value=0.8,
            step=0.01,
            help="æ§åˆ¶ç”Ÿæˆéšæœºæ€§ï¼šè¶Šé«˜è¶Šè‡ªç”±ï¼Œè¶Šä½è¶Šä¿å®ˆã€‚"
        )
        top_k = st.slider(
            "Top-K",
            min_value=1,
            max_value=100,
            value=50,
            step=1,
            help="ä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ªè¯ä¸­é‡‡æ ·ã€‚"
        )
        max_new_tokens = st.slider(
            "æœ€å¤§ç”Ÿæˆé•¿åº¦",
            min_value=10,
            max_value=512,
            value=256,
            step=10,
            help="æ¨¡å‹ä¸€æ¬¡æœ€å¤šç”Ÿæˆå¤šå°‘ tokenã€‚"
        )

    # === åˆå§‹åŒ–æ¨¡å‹ ===
    if "model" not in st.session_state:
        st.session_state.model, st.session_state.tokenizer = load_model_and_tokenizer()

    # === åˆå§‹åŒ–å¯¹è¯å†å² ===
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå„ç§æ–‡æœ¬ï¼ŒåŒ…æ‹¬æ•…äº‹ã€è¯—æ­Œã€ä»£ç ã€æ–‡ç« ç­‰ã€‚æˆ‘çš„ç›®æ ‡æ˜¯å¸®åŠ©ä½ è§£å†³é—®é¢˜ã€æä¾›ä¿¡æ¯ã€å¨±ä¹ç­‰ã€‚"}
        ]

    # === å±•ç¤ºå¯¹è¯å†å² ===
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for msg in st.session_state.messages:
        if msg["role"] == "assistant":
            with st.container():
                st.markdown(f'<div class="message"><div class="avatar">Micro</div><div class="message-text">{msg["content"]}</div></div>', unsafe_allow_html=True)
        elif msg["role"] == "user":
            with st.container():
                st.markdown(f'<div class="message user-message"><div class="message-text">{msg["content"]}</div></div>', unsafe_allow_html=True)

    # === ç”¨æˆ·è¾“å…¥ ===
    prompt = st.chat_input("è¯·åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜...")

    if prompt:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.container():
            st.markdown(f'<div class="message user-message"><div class="message-text">{prompt}</div></div>', unsafe_allow_html=True)

        # ç”Ÿæˆå›å¤
        with st.spinner("ğŸ¤– æ­£åœ¨æ€è€ƒ..."):
            generated_text = sample_output(
                prompt,
                st.session_state.model,
                st.session_state.tokenizer,
                DEVICE,
                MAX_NEW_TOKENS=max_new_tokens,
                TEMPERATURE=temperature,
                TOP_K=top_k
            )
        
        # æ·»åŠ åŠ©æ‰‹å›å¤
        st.session_state.messages.append({"role": "assistant", "content": generated_text})
        with st.container():
            st.markdown(f'<div class="message"><div class="avatar">Micro</div><div class="message-text">{generated_text}</div></div>', unsafe_allow_html=True)

    # === é»˜è®¤ç¤ºä¾‹æŒ‰é’®ï¼ˆå¯é€‰ï¼‰===
    if not st.session_state.messages[0]["content"].startswith("ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹"):
        st.session_state.messages[0]["content"] = "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå„ç§æ–‡æœ¬ï¼ŒåŒ…æ‹¬æ•…äº‹ã€è¯—æ­Œã€ä»£ç ã€æ–‡ç« ç­‰ã€‚æˆ‘çš„ç›®æ ‡æ˜¯å¸®åŠ©ä½ è§£å†³é—®é¢˜ã€æä¾›ä¿¡æ¯ã€å¨±ä¹ç­‰ã€‚"

    # === æ·»åŠ ä¸€ä¸ªç¤ºä¾‹æŒ‰é’®ï¼ˆå¯é€‰ï¼‰===
    if st.button("ğŸ¯ è¯•è¯•é—®æˆ‘ï¼š'ä½ æœ‰ä»€ä¹ˆç‰¹é•¿ï¼Ÿ'", key="example_button"):
        st.session_state.messages.append({"role": "user", "content": "ä½ æœ‰ä»€ä¹ˆç‰¹é•¿ï¼Ÿ"})
        with st.container():
            st.markdown(f'<div class="message user-message"><div class="message-text">ä½ æœ‰ä»€ä¹ˆç‰¹é•¿ï¼Ÿ</div></div>', unsafe_allow_html=True)

        with st.spinner("ğŸ¤– æ­£åœ¨æ€è€ƒ..."):
            example_response = sample_output(
                "ä½ æœ‰ä»€ä¹ˆç‰¹é•¿ï¼Ÿ",
                st.session_state.model,
                st.session_state.tokenizer,
                DEVICE,
                MAX_NEW_TOKENS=128,
                TEMPERATURE=0.8,
                TOP_K=50
            )
        st.session_state.messages.append({"role": "assistant", "content": example_response})
        with st.container():
            st.markdown(f'<div class="message"><div class="avatar">Micro</div><div class="message-text">{example_response}</div></div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­ chat-container

    # === åº•éƒ¨æç¤º ===
    st.markdown('<div class="footer">Â© 2025 MicroGPT | å†…å®¹ç”±AIç”Ÿæˆï¼Œè¯·è°¨æ…ä½¿ç”¨</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()